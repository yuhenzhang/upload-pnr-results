# upload-pnr-results

This repo contains Java code that downloads specific regression test result files from the latest pnr build and uploads them to a HANA DB

## TO-DOs:

Please see the [TO-DO list](TODOs.md) for a comprehensive list explaining the leftover tasks.

## Prerequisites

- [Java JDK 17](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html)
- [Maven](https://maven.apache.org/install.html)
- [Visual Studio Code](https://code.visualstudio.com/download)

## How to use

### Intro: Understand the code

Take a look at [the main classes in this application](code_overview.md) first to understand what each file does.

### Step 1: Configure private properties

After cloning the repo into your project folder. Open the project in VS Code. And in `src/main/resources`, create a file called `config.properties` with the following content:

```
  JENKINS_USERNAME=<your I number>
  JENKINS_API_TOKEN=<your personal API token for this pnr job>
  SAVE_DIR=<local directory name for storing test results/>
  DOWNLOAD_BASE_URL=<url to your pnr job>/lastSuccessfulBuild/artifact/
  JENKINS_URL=<url to your pnr job>/lastSuccessfulBuild/api/json
  DB_HOST=<ex: localhost>
  DB_PORT=<ex: 30041>
  DB_USER=<User>
  DB_PASSWORD=<Password>
  DB_ENCRYPT=true
  DB_VALIDATE_CERTIFICATE=false
```

### Step 2: Create launch.json

1. **Open the Run and Debug view**:
   - Click the Run icon in the Activity Bar (or press `Ctrl+Shift+D`)
2. **Create launch.json**:
   - Click "create a launch.json file"
   - Select "Java" as the environment

### Step 3: Run

1. In the root project folder, run `mvn clean install` to compile/build the project and install the dependencies and plugins from `pom.xml`
2. To run the code, either:
   - In the **Run and Debug** view, click the run button for `App.java` or
   - run the generated jar file in `/target` with command: `java -jar target/upload-pnr-results-1.0-SNAPSHOT.jar`

## Testing

### Execution:

- For unit tests, run `mvn test`
- For integration tests, run `mvn verify`
- If you want to just run unit tests or integration tests independently, then modify the `skiptests` properties under the surefire (for unit tests) or failsafe (for integration tests) plugins in `pom.xml`

### Integration Tests:

- It uses local test files instead of downloading them from Jenkins for flexibility, reproducibility, and stability purposes
- There are three sample test result files available under `src/test/resources/test-data` that are used by default by the integration test to test a normal working scenario. However, if you want to test out different scenarios/create new tests: 1. Create a new folder under `resources/test-data` with a name specific to your scenario and add your corresponding test excel files there 2. Create a new test method in the integration test class that uses these files. For example: <br>

  ```
  @Test
  void testSpecialCaseScenario() throws Exception {
  // Copy files from resources/test-data/special-case/ to test directory
  copySpecificTestFiles("special-case");

    // Test with these specific files
    // ...
   }
  ```

## Viewing HANA DB

### If you want to verify the tables/views created through this workflow, you can view the schema in **DBeaver**:

Create a HANA connection:

- Edition: HANA Cloud
- Host: The host of your HC system
- Port: 443
- Username + Password depends on your credentials, but make sure you have read/write access
- In _Driver Settings_, _Reset to Defaults_ and delete the _Default Port_

If you ran the code and on a local HANA Cloud container with localhost:

- Please follow [this documentation](https://github.wdf.sap.corp/orca/orca_cloud_node/blob/master/docs/getting-started/local-hana-cloud.md) instead for setting up local HANA Cloud
- When adding the connection, make sure you set up a SYSTEM database connection (not generic) and hardcode the port to your port number following the connection properties steps in the **DBeaver setup** section. Or else you won't be able to find/view the same database.

<br>

# Schema Structure

```sql
CREATE SCHEMA REGRESSION_UPLOAD;
SET SCHEMA REGRESSION_UPLOAD;

-- Create dimension table for test scenarios
CREATE COLUMN TABLE TEST_SCENARIO (
    SCENARIO_ID BIGINT NOT NULL GENERATED BY DEFAULT AS IDENTITY (START WITH 1000 INCREMENT BY 1 NO MAXVALUE) PRIMARY KEY,
    NAME NVARCHAR(1024) NOT NULL UNIQUE,    -- e.g., "burn_in", "median", "error"
    ENTITY_TYPE NVARCHAR(1024) NOT NULL     -- "metric" (for burn-in) or "endpoint" (for regression)
);

-- Create fact table for storing metadata about each test execution (one record per Excel column)
CREATE COLUMN TABLE TEST_RUN (
    RUN_ID BIGINT NOT NULL GENERATED BY DEFAULT AS IDENTITY (START WITH 1000 INCREMENT BY 1 NO MAXVALUE) PRIMARY KEY,
    SCENARIO_ID BIGINT NOT NULL,
    JOB_DATE DATE NOT NULL,
    DEPLOYMENT_NAME NVARCHAR(1024) NOT NULL,
    IMAGE_NAME NVARCHAR(1024) NOT NULL,
    BUILD_NUMBER INT NOT NULL,
    JENKINS_JOB_NAME NVARCHAR(1024) NOT NULL,
    FOREIGN KEY (SCENARIO_ID) REFERENCES TEST_SCENARIO(SCENARIO_ID)
);

-- Create fact table for storing the actual test measurements (one record per Excel row in a column)
CREATE COLUMN TABLE TEST_RESULT (
    RESULT_ID BIGINT NOT NULL GENERATED BY DEFAULT AS IDENTITY (START WITH 1000 INCREMENT BY 1 NO MAXVALUE) PRIMARY KEY,
    RUN_ID BIGINT NOT NULL,
    ENTITY_NAME NVARCHAR(1024) NOT NULL,    -- name of metric/endpoint being measured
    DURATION_MS DOUBLE NOT NULL,            -- duration in milliseconds of the test
    FOREIGN KEY (RUN_ID) REFERENCES TEST_RUN(RUN_ID)
);

-- Create views for reporting
CREATE VIEW BURN_IN_RESULTS AS
SELECT
    r.BUILD_NUMBER,
    r.JENKINS_JOB_NAME,
    r.JOB_DATE,
    r.DEPLOYMENT_NAME,
    r.IMAGE_NAME,
    t.ENTITY_NAME AS METRIC_NAME,
    t.DURATION_MS
FROM TEST_RESULT t
JOIN TEST_RUN r ON t.RUN_ID = r.RUN_ID
JOIN TEST_SCENARIO s ON r.SCENARIO_ID = s.SCENARIO_ID
WHERE s.NAME = 'burn_in';

CREATE VIEW REGRESSION_RESULTS AS
SELECT
    r.BUILD_NUMBER,
    r.JENKINS_JOB_NAME,
    s.NAME AS SCENARIO_TYPE,
    r.JOB_DATE,
    r.DEPLOYMENT_NAME,
    r.IMAGE_NAME,
    t.ENTITY_NAME AS ENDPOINT_URI,
    t.DURATION_MS
FROM TEST_RESULT t
JOIN TEST_RUN r ON t.RUN_ID = r.RUN_ID
JOIN TEST_SCENARIO s ON r.SCENARIO_ID = s.SCENARIO_ID
WHERE s.ENTITY_TYPE = 'endpoint';
```

## Main Advantages

1. **Jenkins Integration**

   - Direct job traceability via `BUILD_NUMBER` and `JENKINS_JOB_NAME`
   - Unique constraint prevents duplicate uploads from same build
   - Supports unlimited test scenarios/metrics and cross-build comparisons

2. **Scalable Design**
   - Modular design separates volatile results (`TEST_RESULT`) from stable metadata (`TEST_RUN`)
   - Dual-purpose scenario table handles both metric and endpoint tests
   ```sql
   -- Easy to add new test types without schema changes
   INSERT INTO TEST_SCENARIO VALUES
   (7, 'throughput', 'endpoint');
   ```
